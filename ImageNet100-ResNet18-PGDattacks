{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2491748,"sourceType":"datasetVersion","datasetId":1500837}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-04T17:40:43.554762Z","iopub.execute_input":"2024-08-04T17:40:43.555142Z","iopub.status.idle":"2024-08-04T17:43:20.661417Z","shell.execute_reply.started":"2024-08-04T17:40:43.555103Z","shell.execute_reply":"2024-08-04T17:43:20.660322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Enhanced ResNet18 with PGD through ImageNet100\nThis is the enhanced version of the ImageNet10 code to create at least 70% accuracy of the ResNet18 model based on the ImageNet100 dataset. There will be PGD attacks performed on it as well. ","metadata":{}},{"cell_type":"markdown","source":"# Loading the dataset with labels","metadata":{}},{"cell_type":"code","source":"import json\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport cv2\n\n# Load labels from JSON file\nwith open('/kaggle/input/imagenet100/Labels.json', 'r') as f:\n    labels = json.load(f)\n\n# Create a mapping from class ID to class name\nid_to_class = {str(k): v for k, v in labels.items()}\n\n# Function to display an image with its label\ndef show_image_with_label(image_path, label):\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    plt.imshow(image)\n    plt.title(f'Label: {label}')\n    plt.axis('off')\n    plt.show()\n\n# Directories containing the images\nbase_train_dir = '/kaggle/input/imagenet100'\nval_dir = os.path.join(base_train_dir, 'val.X')\ntrain_dirs = [os.path.join(base_train_dir, f'train.X{i}') for i in range(1, 5)]\n\n# Helper function to get a random sample of images from a directory\ndef get_random_images(data_dirs, num_samples=5):\n    images = []\n    all_files = []\n    for data_dir in data_dirs:\n        for label_id in os.listdir(data_dir):\n            class_name = id_to_class.get(label_id, 'Unknown')\n            files = os.listdir(os.path.join(data_dir, label_id))\n            all_files.extend([(os.path.join(data_dir, label_id, filename), class_name) for filename in files])\n\n    selected_files = random.sample(all_files, num_samples)\n    for image_path, class_name in selected_files:\n        images.append((image_path, class_name))\n    return images\n\n# Get random images from validation set\nval_images = get_random_images([val_dir], 5)\n\n# Get random images from all training directories\ntrain_images = get_random_images(train_dirs, 5)\n\n# Display random validation images\nprint(\"Random Validation Images:\")\nfor image_path, label in val_images:\n    show_image_with_label(image_path, label)\n\n# Display random training images\nprint(\"Random Training Images:\")\nfor image_path, label in train_images:\n    show_image_with_label(image_path, label)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:43:20.663405Z","iopub.execute_input":"2024-08-04T17:43:20.663940Z","iopub.status.idle":"2024-08-04T17:43:24.221674Z","shell.execute_reply.started":"2024-08-04T17:43:20.663907Z","shell.execute_reply":"2024-08-04T17:43:24.220800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Organize Data into Validation and Training Sets","metadata":{}},{"cell_type":"code","source":"# Creating the transforms\nimport torch\nimport torchvision\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(30),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:43:24.226899Z","iopub.execute_input":"2024-08-04T17:43:24.227166Z","iopub.status.idle":"2024-08-04T17:43:28.876001Z","shell.execute_reply.started":"2024-08-04T17:43:24.227142Z","shell.execute_reply":"2024-08-04T17:43:28.875156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a custom dataset class\nclass MultiFolderDataset(Dataset):\n    def __init__(self, folders, transform=None):\n        self.samples = []\n        self.transform = transform\n        for folder in folders:\n            for label_id in os.listdir(folder):\n                class_name = id_to_class.get(label_id, 'Unknown')\n                files = os.listdir(os.path.join(folder, label_id))\n                self.samples.extend([(os.path.join(folder, label_id, filename), label_id) for filename in files])\n        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(sorted(id_to_class.keys()))}\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        path, label = self.samples[idx]\n        image = Image.open(path).convert(\"RGB\")\n        if self.transform is not None:\n            image = self.transform(image)\n        label = self.class_to_idx[label]\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:43:28.877394Z","iopub.execute_input":"2024-08-04T17:43:28.877787Z","iopub.status.idle":"2024-08-04T17:43:28.885998Z","shell.execute_reply.started":"2024-08-04T17:43:28.877760Z","shell.execute_reply":"2024-08-04T17:43:28.885073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.datasets as datasets\n# Creating the Datasets\ntrain_dataset = MultiFolderDataset(train_dirs, transform=transform)\nval_dataset = datasets.ImageFolder(val_dir, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:43:28.887185Z","iopub.execute_input":"2024-08-04T17:43:28.887459Z","iopub.status.idle":"2024-08-04T17:43:29.421607Z","shell.execute_reply.started":"2024-08-04T17:43:28.887436Z","shell.execute_reply":"2024-08-04T17:43:29.420867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training Configuration\n* Define Hyperparameters\n* Set up DataLoaders","metadata":{}},{"cell_type":"code","source":"# DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:43:29.422638Z","iopub.execute_input":"2024-08-04T17:43:29.422923Z","iopub.status.idle":"2024-08-04T17:43:29.427709Z","shell.execute_reply.started":"2024-08-04T17:43:29.422900Z","shell.execute_reply":"2024-08-04T17:43:29.426875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the Model\n* Train model with hyperparameters\n* Tune hyperparameters systematically\n* Fine-tune the model","metadata":{}},{"cell_type":"code","source":"# Setting up device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:43:29.428910Z","iopub.execute_input":"2024-08-04T17:43:29.429215Z","iopub.status.idle":"2024-08-04T17:43:29.483152Z","shell.execute_reply.started":"2024-08-04T17:43:29.429190Z","shell.execute_reply":"2024-08-04T17:43:29.482246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import models\n\nmodel = models.resnet18(pretrained=True)\nmodel.fc = torch.nn.Linear(model.fc.in_features, 100)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:43:29.484229Z","iopub.execute_input":"2024-08-04T17:43:29.484507Z","iopub.status.idle":"2024-08-04T17:43:30.343751Z","shell.execute_reply.started":"2024-08-04T17:43:29.484483Z","shell.execute_reply":"2024-08-04T17:43:30.342852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n    \nmodel.fc = torch.nn.Linear(model.fc.in_features, 100)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:43:30.347042Z","iopub.execute_input":"2024-08-04T17:43:30.347734Z","iopub.status.idle":"2024-08-04T17:43:30.355479Z","shell.execute_reply.started":"2024-08-04T17:43:30.347698Z","shell.execute_reply":"2024-08-04T17:43:30.354403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:43:30.356635Z","iopub.execute_input":"2024-08-04T17:43:30.356945Z","iopub.status.idle":"2024-08-04T17:43:30.366157Z","shell.execute_reply.started":"2024-08-04T17:43:30.356921Z","shell.execute_reply":"2024-08-04T17:43:30.365399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensure CUDA is available\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\n\n# Setting up device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Import time module to measure time taken for each epoch\nimport time\nfrom tqdm import tqdm\n\n# Training loop\nnum_epochs = 5\n\nfor epoch in range(num_epochs):\n    start_time = time.time()\n    model.train()  # Set model to training mode\n    running_loss = 0.0\n    \n    # Training phase\n    for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\")):\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()  # Zero the parameter gradients\n        \n        outputs = model(inputs)  # Forward pass\n        loss = criterion(outputs, labels)  # Compute loss\n        loss.backward()  # Backward pass\n        optimizer.step()  # Update weights\n        \n        running_loss += loss.item() * inputs.size(0)  # Update running loss\n        \n        if i % 100 == 0:  # Print every 100 batches\n            print(f\"Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n    \n    epoch_loss = running_loss / len(train_loader.dataset)  # Compute epoch loss\n    \n    # Validation phase\n    model.eval()  # Set model to evaluation mode\n    val_loss = 0.0\n    correct1 = 0\n    correct5 = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            outputs = model(inputs)  # Forward pass\n            loss = criterion(outputs, labels)  # Compute loss\n            \n            val_loss += loss.item() * inputs.size(0)  # Update validation loss\n            \n            # Calculate accuracy\n            _, pred1 = outputs.topk(1, 1, True, True)\n            _, pred5 = outputs.topk(5, 1, True, True)\n            correct1 += pred1.eq(labels.view(-1, 1).expand_as(pred1)).sum().item()\n            correct5 += pred5.eq(labels.view(-1, 1).expand_as(pred5)).sum().item()\n            total += labels.size(0)\n    \n    epoch_val_loss = val_loss / len(val_loader.dataset)  # Compute epoch validation loss\n    top1_acc = correct1 / total  # Compute top-1 accuracy\n    top5_acc = correct5 / total  # Compute top-5 accuracy\n    \n    end_time = time.time()\n    epoch_duration = end_time - start_time\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}] - Time: {epoch_duration:.2f}s')\n    print(f'Train Loss: {epoch_loss:.4f}')\n    print(f'Validation Loss: {epoch_val_loss:.4f}')\n    print(f'Top-1 Accuracy: {top1_acc:.4f}, Top-5 Accuracy: {top5_acc:.4f}')\n\nprint('Training complete')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T17:48:46.412631Z","iopub.execute_input":"2024-08-04T17:48:46.412988Z","iopub.status.idle":"2024-08-04T19:29:38.895563Z","shell.execute_reply.started":"2024-08-04T17:48:46.412959Z","shell.execute_reply":"2024-08-04T19:29:38.894532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing and evaluate PGD attacks","metadata":{}},{"cell_type":"code","source":"pip install torchattacks","metadata":{"execution":{"iopub.status.busy":"2024-08-04T19:36:32.654726Z","iopub.execute_input":"2024-08-04T19:36:32.655385Z","iopub.status.idle":"2024-08-04T19:36:47.073303Z","shell.execute_reply.started":"2024-08-04T19:36:32.655353Z","shell.execute_reply":"2024-08-04T19:36:47.072020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchattacks\nfrom tqdm import tqdm\nimport time\n\npgd = torchattacks.PGD(model, eps=0.3, alpha=2/255, steps=40)\n\ndef evaluate_under_attack(loader, model, attack):\n    model.eval()\n    correct = 0\n    total = 0\n    batch_times = []\n    progress_bar = tqdm(enumerate(loader), total=len(loader), desc=\"Evaluating\")\n    \n    for i, (inputs, labels) in progress_bar:\n        start_time = time.time()\n        \n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # Enable gradients for the inputs\n        inputs.requires_grad = True\n        \n        adv_inputs = attack(inputs, labels)\n        outputs = model(adv_inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Disable gradients for the inputs\n        inputs.requires_grad = False\n\n        batch_time = time.time() - start_time\n        batch_times.append(batch_time)\n        \n        # Update progress bar with batch accuracy and average batch time\n        progress_bar.set_postfix(batch_accuracy=(correct / total), avg_batch_time=sum(batch_times) / len(batch_times))\n    \n    accuracy = correct / total\n    return accuracy\n\nadv_accuracy = evaluate_under_attack(val_loader, model, pgd)\nprint(f'Adversarial Accuracy: {adv_accuracy*100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T19:36:47.075947Z","iopub.execute_input":"2024-08-04T19:36:47.076469Z","iopub.status.idle":"2024-08-04T19:44:14.315895Z","shell.execute_reply.started":"2024-08-04T19:36:47.076428Z","shell.execute_reply":"2024-08-04T19:44:14.314895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Implementing and evaluate CW attacks","metadata":{}},{"cell_type":"code","source":"import torchattacks\nfrom tqdm import tqdm\n\n# Initialize Carlini-Wagner attack with fewer steps for quicker evaluation\ncw = torchattacks.CW(model, c=1e-4, kappa=0, steps=100, lr=0.01)  # Reduced steps for speed\n\ndef evaluate_under_attack(loader, model, attack):\n    model.eval()\n    correct = 0\n    total = 0\n    progress_bar = tqdm(enumerate(loader), total=len(loader), desc=\"Evaluating CW Attack\")\n    \n    for i, (inputs, labels) in progress_bar:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        # Generate adversarial examples\n        adv_inputs = attack(inputs, labels)\n        \n        # Get model predictions on adversarial examples\n        outputs = model(adv_inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        \n        # Update counters\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Update progress bar with batch accuracy\n        progress_bar.set_postfix(batch_accuracy=(correct / total))\n    \n    accuracy = correct / total\n    return accuracy\n\n# Evaluate the model under CW attack\nadv_accuracy_cw = evaluate_under_attack(val_loader, model, cw)\nprint(f'Adversarial Accuracy under CW Attack: {adv_accuracy_cw * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-08-04T20:03:06.557486Z","iopub.execute_input":"2024-08-04T20:03:06.557887Z","iopub.status.idle":"2024-08-04T20:07:28.840708Z","shell.execute_reply.started":"2024-08-04T20:03:06.557843Z","shell.execute_reply":"2024-08-04T20:07:28.839867Z"},"trusted":true},"execution_count":null,"outputs":[]}]}